{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StringType\n",
    "import docker\n",
    "\n",
    "import requests\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "import shutil\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from new_project_pipeline import predict_tags_for_new_project"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predict_tags_for_new_project(\"https://github.com/zuevmaxim/itmo-ibd.git\", )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Start Spark session\n",
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .appName(\"Handle new project pipline\")\n",
    "         .getOrCreate())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_tags_for_new_project(\"https://github.com/zuevmaxim/itmo-ibd.git\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Start Spark session\n",
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .appName(\"Handle new project pipline\")\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_dir(dir_path: str):\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def remove_dir(dir_path: str):\n",
    "    shutil.rmtree(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "PATH_TO_CLONE_REPO = \"./test_project\"\n",
    "GIT_CLONE_LINK=\"https://github.com/zuevmaxim/itmo-ibd.git\"\n",
    "PROJECT_OWNER = GIT_CLONE_LINK.split(\"/\")[-2]\n",
    "PROJECT_NAME = GIT_CLONE_LINK.split(\"/\")[-1].split(\".git\")[0]\n",
    "PROJECT_PATH = os.path.join(PATH_TO_CLONE_REPO, PROJECT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "create_dir(PROJECT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into './test_project/itmo-ibd'...\n",
      "\u001B[KUpdating files: 100% (160/160), done.\n"
     ]
    }
   ],
   "source": [
    "#First of all clone repo\n",
    "p = subprocess.Popen(['git', 'clone', GIT_CLONE_LINK, PROJECT_PATH, '--depth', '1'])\n",
    "return_code = p.wait()\n",
    "if return_code != 0:\n",
    "    logging.info(f'Error while cloning {GIT_CLONE_LINK}!')\n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Compute extensions metrics\n",
    "cont_extensions = defaultdict(int)\n",
    "for root, _, files in os.walk(PROJECT_PATH):\n",
    "    for filename in files:\n",
    "        extension = os.path.splitext(filename)[1]\n",
    "        cont_extensions[extension] += 1\n",
    "extensions_metrics = []\n",
    "for extension, count in cont_extensions.items():\n",
    "    extensions_metrics.append((f\"{PROJECT_NAME}\" ,extension, count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "extensions_metrics_dataset = spark.createDataFrame(extensions_metrics).toDF(*[\"project_name\", \"extension\", \"count\"]).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "extensions_metrics_dataset.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def rename_extension(package_name):\n",
    "    return f\"extension#{package_name}\"\n",
    "\n",
    "udf_rename_extension = F.udf(rename_extension, returnType=StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "extensions_metrics_dataset = extensions_metrics_dataset.select(\"project_name\", udf_rename_extension(\"extension\").alias(\"extension\"), \"count\")\n",
    "extensions_metrics_dataset.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# generate unique folders every time\n",
    "PATH_TO_LUPA_KOTLIN_OUTPUT = \"/home/Dmitry.Pogrebnoy/Desktop/tmp_lupa_kotlin_output\"\n",
    "PATH_TO_LUPA_PYTHON_OUTPUT = \"/home/Dmitry.Pogrebnoy/Desktop/tmp_lupa_python_output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "create_dir(PATH_TO_LUPA_KOTLIN_OUTPUT)\n",
    "create_dir(PATH_TO_LUPA_PYTHON_OUTPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "docker_volumes= {\n",
    "    f'{PATH_TO_CLONE_REPO}' : {'bind' : '/data', 'mode' : 'ro'},\n",
    "    f'{PATH_TO_LUPA_PYTHON_OUTPUT}' : {'bind' : '/output_python', 'mode' : 'rw'},\n",
    "    f'{PATH_TO_LUPA_KOTLIN_OUTPUT}' : {'bind' : '/output_kotlin', 'mode' : 'rw'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# run lupa docker to extract imports\n",
    "docker_client = docker.from_env()\n",
    "docker_client.containers.run('pogrebnoy/ibd-lupa-extract-imports:1.0.0',\n",
    "                                         auto_remove=True,\n",
    "                                         #user=f\"{os.getuid()}\", # Fails lupa with Exception in thread \"main\" java.lang.RuntimeException: Could not create parent directory for lock file /Lupa/?/.gradle/wrapper/dists/gradle-6.8.3-bin/7ykxq50lst7lb7wx1nijpicxn/gradle-6.8.3-bin.zip.lck\n",
    "                                         stderr=True,\n",
    "                                         volumes=docker_volumes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Gathering all imports data to one dataset\n",
    "python_imports_dataset = spark.read.csv(os.path.join(PATH_TO_LUPA_PYTHON_OUTPUT, \"import_statements_data.csv\"), header=True).cache()\n",
    "python_imports_dataset.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "kotlin_imports_dataset = spark.read.csv(os.path.join(PATH_TO_LUPA_KOTLIN_OUTPUT, \"import_directives_data.csv\"), header=True).cache()\n",
    "kotlin_imports_dataset.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "imports_dataset = python_imports_dataset.union(kotlin_imports_dataset).cache()\n",
    "imports_dataset.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "PATH_TO_IMPORT_TO_PACKAGE_DATASET=\"/home/Dmitry.Pogrebnoy/Desktop/itmo-ibd/data/full_import_dataset/lupa_import_grouping/output/import_by_package.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import_to_package_dataset = spark.read.csv(PATH_TO_IMPORT_TO_PACKAGE_DATASET, header=True)\n",
    "import_to_package_dataset.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import_to_package_dataset = import_to_package_dataset.toPandas()\n",
    "import_to_package_dict = dict(zip(import_to_package_dataset[\"import\"], import_to_package_dataset[\"package\"]))\n",
    "import_to_package_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_package_by_import(lib_import):\n",
    "    if lib_import in import_to_package_dict:\n",
    "        return import_to_package_dict[lib_import]\n",
    "    else:\n",
    "        return lib_import\n",
    "\n",
    "map_import_to_package = F.udf(get_package_by_import, returnType=StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "full_import_dataset = imports_dataset.select(\n",
    " \"*\", map_import_to_package(\"import\").alias(\"package\")\n",
    ").cache()\n",
    "full_import_dataset.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Make final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "intermediate_dataframe = (full_import_dataset.select(\"*\")\n",
    "                          .groupby(['project_name', 'package'])\n",
    "                          .agg(F.count(\"*\").alias(\"count_different_import\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "intermediate_dataframe.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def rename_package(package_name):\n",
    "    return f\"package#{package_name}\"\n",
    "\n",
    "udf_rename_package = F.udf(rename_package, returnType=StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "intermediate_dataframe = intermediate_dataframe.select(\n",
    " \"project_name\", udf_rename_package(\"package\").alias(\"package\")\n",
    ").cache()\n",
    "intermediate_dataframe.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pivot_package_dataframe = intermediate_dataframe.groupby(\"project_name\").pivot(\"package\").agg(F.count(\"*\"))\n",
    "pivot_package_dataframe.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pivot_ext_count_dataset = extensions_metrics_dataset.groupby(\"project_name\").pivot(\"extension\").agg(F.first(\"count\"))\n",
    "pivot_ext_count_dataset.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "final_dataset = pivot_package_dataframe.join(pivot_ext_count_dataset, [\"project_name\"])\n",
    "final_dataset.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "final_dataset_dict = final_dataset.collect()[0].asDict(True)\n",
    "final_dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "PATH_TO_COLUMN_DATASET = \"/home/Dmitry.Pogrebnoy/Desktop/itmo-ibd/data/pipeline/final_columns.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "columns_dataset = spark.read.csv(PATH_TO_COLUMN_DATASET, header=True).toPandas()[\"column_name\"].to_list()\n",
    "final_data_for_prediction = []\n",
    "for item in columns_dataset:\n",
    "    if item in final_dataset_dict:\n",
    "        final_data_for_prediction.append(final_dataset_dict.get(item))\n",
    "    else:\n",
    "        final_data_for_prediction.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "final_data_for_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Not all zeros\n",
    "sum(final_data_for_prediction[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Then we should pass the data to predictor and that's it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# bla bla bla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "PATH_TO_TAG_DATASET = \"/home/Dmitry.Pogrebnoy/Desktop/itmo-ibd/data/pipeline/final_tags.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tags_dataset = spark.read.csv(PATH_TO_COLUMN_DATASET, header=True).toPandas()[\"tag_name\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(tags_dataset[0])\n",
    "print(tags_dataset[10])\n",
    "print(tags_dataset[20])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}